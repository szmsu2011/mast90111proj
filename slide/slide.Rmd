---
title: "MAST90111 Advanced Statistical Modelling"
subtitle: "Predicting Salary of Major League Baseball Players"
author: "Stephen Su, Thomas Black"
date: "October 2024"
output:
  xaringan::moon_reader:
    nature:
      highlightLines: true
    css: xaringan-themer.css
---

```{r setup, echo = FALSE, cache = FALSE, message = FALSE}
library(knitr)
options(
  htmltools.dir.version = FALSE, htmltools.preserve.raw = FALSE,
  tibble.width = 60, tibble.print_min = 6
)
opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE, comment = "#>",
  fig.retina = 3, fig.align = "center", fig.show = "hold", dpi = 110,
  dev.args = list(png = list(type = "cairo"))
)
```
```{r xaringan-themer, include = FALSE, warning = FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#035AA6",
  header_font_google = google_font("Josefin Sans"),
  text_font_google = google_font("Montserrat", "400", "400i"),
  code_font_google = google_font("Fira Mono")
)
```

```{r external, include = FALSE, cache = FALSE}
read_chunk("../R/main.R")
```
```{r lib, include = FALSE}
```

## Introduction

- Aim: predict **salary** (log scaled) of major league baseball players by cumulated **hits** and **years** in profession.

- Assumption: all variables above are continuous on $\mathbb{R}$. Also, all conditions mentioned in lecture hold.

- A data set of 263 major league players from the 1986 and 1987 seasons (James et al., 2013).

- Randomly sampled: 200 observations in training set, 63 in test set.

```{r data, echo = 2:4}
```

- Nonparametric/semiparametric models are fitted, using the data in the training set, as well as their conventional parametric counterparts.

- The predictive performance of the methods are evaluated and compared, using the data in the test set.

---

## Univariate prediction

- Suppose only the log **salary** variable $Y$ is observable.

- Sample mean: best point predictor in terms of $\ell_2$-loss.

- Interval predictor: suppose $\hat{f}$ is an estimate of the p.d.f. of $Y$, then a central $(1 - \alpha)$ confidence interval of prediction is

$$\left\{[a, b] : \int_{-\infty}^a \hat{f}(x)dx = \frac{\alpha}{2}, \int_{-\infty}^b \hat{f}(x)dx = 1 - \frac{\alpha}{2}\right\}$$

- If we assume Normality (a parametric approach): $Y \sim \text{N}(\mu, \sigma^2)$ then

$$\hat{f}(x) = \phi\left(\frac{x - \hat\mu}{\hat\sigma}\right)$$

- Kernel density estimation (a nonparametric approach)

$$\hat{f}(x) = \frac{1}{nh} \sum_{i = 1}^n K\left(\frac{x - Y_i}{h}\right) \text{ for some } h > 0$$

---

## Univariate prediction: evaluation

- Let $p$ be the proportion of **test** data points included inside the **trained** 50% central confidence interval, we have the exact Binomial test (Clopper & Pearson, 1934) given by

$$H_0: p = 0.5; H_1: p \neq 0.5$$

- Normal: $35$% (95% CI: $[0.23, 0.48]$, p-value: $0.0226$).

- KDE (ROT and LSCV): $44$% (95% CI: $[0.32, 0.58]$, p-value: $0.45$).

```{r kde, include = FALSE, echo = FALSE}
```
```{r univar-fit-plot, echo = FALSE, dpi = 400, fig.height = 2.6}
```

---

## Bivariate regression

- Suppose we also observe the cumulated number of **hits** $X_1$.

- We wish to estimate $m(x) = \mathbb{E}(Y | X_1 = x)$.

- For observation $(X_{n + 1}, Y_{n + 1})$, use $\hat{m}(X_{n + 1})$ as the predictor for the "unknown" (test) $Y_{n + 1}$.

- Assume Normality - linear regression (a parametric approach); by OLS:

$$m(x) = \beta_0 + \beta_1x$$

- Local linear regression (a nonparametric approach): $p = 1$ as we are estimating the zero derivative; by LSCV.

$$m(x) \approx m(x_0) + m'(x_0)(x - x_0)$$

- Penalised cubic spline regression (a nonparametric approach): with $L = \min\{200 / 4, 35\} = 35$; by GCV.

$$m(x) = s(x)$$

---

## Bivariate regression: evaluation

```{r bivar-reg, include = FALSE, echo = FALSE}
```
```{r bivar-reg-fit-plot, echo = FALSE, dpi = 400, fig.height = 3.2}
```
```{r bivar-reg-eval, echo = FALSE}
```

---

## Open and reproducible work

The source files and version histories are available on **Github**.

**Install required dependencies (R console)**

```r
install.packages("tidyverse")
install.packages("xaringan")
install.packages("xaringanthemer")
install.packages("np")
install.packages("mgcv")
install.packages("tinytex")
tinytex::install_tinytex()
```

**Usage (command line)**

```zsh
git clone https://github.com/szmsu2011/mast90111proj
cd mast90111proj
R
```
```r
rmarkdown::render("report/report.Rmd")
rmarkdown::render("slide/slide.Rmd")
```

---

## References

- Clopper, C. J., & Pearson, E. S. (1934). The use of confidence or fiducial limits illustrated in the case of the binomial. *Biometrika*, *26*(4), 404-413. [https://doi.org/10.2307/2331986](https://doi.org/10.2307/2331986)

- James, G., Witten, D., Hastie, T., Tibshirani, R., et al. (2013). *An introduction to statistical learning*. Springer.
